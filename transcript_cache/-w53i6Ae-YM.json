{
  "video_id": "-w53i6Ae-YM",
  "duration": 243.56,
  "full_transcript": [
    {
      "text": "Yesterday, Chinese company Alibaba",
      "start": 0.08,
      "duration": 4.08
    },
    {
      "text": "dropped a brand new openweight long",
      "start": 2.32,
      "duration": 4.24
    },
    {
      "text": "horizon mixture of experts agent coding",
      "start": 4.16,
      "duration": 5.04
    },
    {
      "text": "model named Quen 3 coder. And amazingly,",
      "start": 6.56,
      "duration": 4.56
    },
    {
      "text": "it's the first openweight model that",
      "start": 9.2,
      "duration": 3.76
    },
    {
      "text": "matches the programming performance of",
      "start": 11.12,
      "duration": 4.24
    },
    {
      "text": "Claude 4, the undisputed leader of AI",
      "start": 12.96,
      "duration": 4.56
    },
    {
      "text": "vibe coding tools at the present time.",
      "start": 15.36,
      "duration": 4.48
    },
    {
      "text": "Not only is the Quen 3 coder model open,",
      "start": 17.52,
      "duration": 4.16
    },
    {
      "text": "but they also just released a brand new",
      "start": 19.84,
      "duration": 4.0
    },
    {
      "text": "CLI tool forked from the recently open",
      "start": 21.68,
      "duration": 4.16
    },
    {
      "text": "source Gemini CLI that can take",
      "start": 23.84,
      "duration": 3.679
    },
    {
      "text": "advantage of all the models agentic",
      "start": 25.84,
      "duration": 3.92
    },
    {
      "text": "properties like the ability to run,",
      "start": 27.519,
      "duration": 4.16
    },
    {
      "text": "execute, and test your code from the",
      "start": 29.76,
      "duration": 3.92
    },
    {
      "text": "command line. That's terrifying news for",
      "start": 31.679,
      "duration": 3.921
    },
    {
      "text": "any programmer still left with a job,",
      "start": 33.68,
      "duration": 3.92
    },
    {
      "text": "but mathematicians are also on life",
      "start": 35.6,
      "duration": 3.84
    },
    {
      "text": "support right now because both Google",
      "start": 37.6,
      "duration": 4.24
    },
    {
      "text": "and OpenAI just achieved gold medals in",
      "start": 39.44,
      "duration": 4.639
    },
    {
      "text": "the International Mathematical Olympiad.",
      "start": 41.84,
      "duration": 3.84
    },
    {
      "text": "In today's video, we'll take a look at",
      "start": 44.079,
      "duration": 3.521
    },
    {
      "text": "the latest AI breakthroughs and find out",
      "start": 45.68,
      "duration": 4.08
    },
    {
      "text": "if Quen 3 coder can actually compete",
      "start": 47.6,
      "duration": 5.36
    },
    {
      "text": "with Claude 4. It is July 23rd, 2025,",
      "start": 49.76,
      "duration": 5.04
    },
    {
      "text": "and you're watching the code report.",
      "start": 52.96,
      "duration": 3.84
    },
    {
      "text": "Just last week, the open model scene got",
      "start": 54.8,
      "duration": 4.48
    },
    {
      "text": "a big upgrade with the Chinese Kimmy K2,",
      "start": 56.8,
      "duration": 4.72
    },
    {
      "text": "but now Quen 3 coder pushes things even",
      "start": 59.28,
      "duration": 4.64
    },
    {
      "text": "further. The model was trained on 7.5",
      "start": 61.52,
      "duration": 5.36
    },
    {
      "text": "trillion tokens with a 70% code ratio.",
      "start": 63.92,
      "duration": 4.239
    },
    {
      "text": "In other words, it's seen a billion",
      "start": 66.88,
      "duration": 2.8
    },
    {
      "text": "times more code than the average",
      "start": 68.159,
      "duration": 3.521
    },
    {
      "text": "developer with 50 years of experience.",
      "start": 69.68,
      "duration": 3.759
    },
    {
      "text": "They even use their previous model to",
      "start": 71.68,
      "duration": 3.759
    },
    {
      "text": "clean up noisy training data, the highly",
      "start": 73.439,
      "duration": 3.761
    },
    {
      "text": "meta process where AI basically",
      "start": 75.439,
      "duration": 3.601
    },
    {
      "text": "determines which data to use to train",
      "start": 77.2,
      "duration": 3.52
    },
    {
      "text": "itself. When it comes to the training",
      "start": 79.04,
      "duration": 3.439
    },
    {
      "text": "process, they use something called long",
      "start": 80.72,
      "duration": 3.84
    },
    {
      "text": "horizon reinforcement learning across",
      "start": 82.479,
      "duration": 4.481
    },
    {
      "text": "20,000 parallel environments. The model",
      "start": 84.56,
      "duration": 4.0
    },
    {
      "text": "actually tries to solve real world",
      "start": 86.96,
      "duration": 3.519
    },
    {
      "text": "problems in real environments where it's",
      "start": 88.56,
      "duration": 3.84
    },
    {
      "text": "executing and testing code. You can",
      "start": 90.479,
      "duration": 3.521
    },
    {
      "text": "think of Quen's training infrastructure",
      "start": 92.4,
      "duration": 3.759
    },
    {
      "text": "like a coding boot camp with 20,000",
      "start": 94.0,
      "duration": 3.68
    },
    {
      "text": "graduates all working on the same",
      "start": 96.159,
      "duration": 3.361
    },
    {
      "text": "problem simultaneously, except they",
      "start": 97.68,
      "duration": 4.0
    },
    {
      "text": "never get tired, never argue, and never",
      "start": 99.52,
      "duration": 3.919
    },
    {
      "text": "ask, \"Is this a breaking change?\" And",
      "start": 101.68,
      "duration": 3.28
    },
    {
      "text": "the end result speaks for itself in",
      "start": 103.439,
      "duration": 3.121
    },
    {
      "text": "these benchmarks. Based on this",
      "start": 104.96,
      "duration": 3.6
    },
    {
      "text": "benchmark, Quen is outperforming Kimmy",
      "start": 106.56,
      "duration": 5.199
    },
    {
      "text": "and GPT4.1 and almost on par with Claude",
      "start": 108.56,
      "duration": 5.28
    },
    {
      "text": "4, but doing so with a much smaller",
      "start": 111.759,
      "duration": 4.0
    },
    {
      "text": "model size, which is important because",
      "start": 113.84,
      "duration": 3.279
    },
    {
      "text": "the bigger the model, the more",
      "start": 115.759,
      "duration": 3.601
    },
    {
      "text": "electricity and GPUs you need to run it.",
      "start": 117.119,
      "duration": 4.081
    },
    {
      "text": "What's also really impressive about Quen",
      "start": 119.36,
      "duration": 4.96
    },
    {
      "text": "3 coder is that it has a 256,000 token",
      "start": 121.2,
      "duration": 5.12
    },
    {
      "text": "context window that can stretch up to 1",
      "start": 124.32,
      "duration": 3.999
    },
    {
      "text": "million tokens. For reference, that's",
      "start": 126.32,
      "duration": 3.6
    },
    {
      "text": "enough to hold the entire codebase of",
      "start": 128.319,
      "duration": 3.441
    },
    {
      "text": "most startups and all of their technical",
      "start": 129.92,
      "duration": 3.76
    },
    {
      "text": "debt. Quen 3 coder is an openweight",
      "start": 131.76,
      "duration": 3.199
    },
    {
      "text": "model, but if you think you're going to",
      "start": 133.68,
      "duration": 3.199
    },
    {
      "text": "run it locally on your laptop, it's time",
      "start": 134.959,
      "duration": 4.081
    },
    {
      "text": "for a reality check. To harness the full",
      "start": 136.879,
      "duration": 4.241
    },
    {
      "text": "girth of the 480 billion parameter",
      "start": 139.04,
      "duration": 3.52
    },
    {
      "text": "version, you would need tens of",
      "start": 141.12,
      "duration": 3.119
    },
    {
      "text": "thousands, if not hundreds of thousands",
      "start": 142.56,
      "duration": 3.759
    },
    {
      "text": "of dollars worth of GPUs along with a",
      "start": 144.239,
      "duration": 3.521
    },
    {
      "text": "large wallet to pay the electricity",
      "start": 146.319,
      "duration": 3.361
    },
    {
      "text": "bill. Realistically, to try it, you'd",
      "start": 147.76,
      "duration": 3.6
    },
    {
      "text": "want to get an API key from a cloud",
      "start": 149.68,
      "duration": 3.279
    },
    {
      "text": "provider, then hook it up to the new",
      "start": 151.36,
      "duration": 3.92
    },
    {
      "text": "Quen CLI tool, which again is a fork of",
      "start": 152.959,
      "duration": 4.401
    },
    {
      "text": "the Gemini CLI. Overall, this does",
      "start": 155.28,
      "duration": 4.0
    },
    {
      "text": "appear to be a big leap forward for open",
      "start": 157.36,
      "duration": 3.84
    },
    {
      "text": "coding models. But I doubt that it will",
      "start": 159.28,
      "duration": 3.36
    },
    {
      "text": "make much of a dent in Claude's",
      "start": 161.2,
      "duration": 3.2
    },
    {
      "text": "dominance in the coding world. To be",
      "start": 162.64,
      "duration": 3.52
    },
    {
      "text": "Claude, a company needs to release a",
      "start": 164.4,
      "duration": 3.199
    },
    {
      "text": "model that's not only open and",
      "start": 166.16,
      "duration": 3.84
    },
    {
      "text": "inexpensive, but that surpasses Claude's",
      "start": 167.599,
      "duration": 4.481
    },
    {
      "text": "capabilities by a significant margin.",
      "start": 170.0,
      "duration": 4.08
    },
    {
      "text": "Like OpenAI was recently supposed to",
      "start": 172.08,
      "duration": 3.84
    },
    {
      "text": "release its own Open model, but that's",
      "start": 174.08,
      "duration": 3.439
    },
    {
      "text": "been delayed with the rumor for the",
      "start": 175.92,
      "duration": 3.44
    },
    {
      "text": "delay being that these Chinese models",
      "start": 177.519,
      "duration": 3.681
    },
    {
      "text": "would absolutely crush it. That's just",
      "start": 179.36,
      "duration": 3.76
    },
    {
      "text": "one of many L's taken by OpenAI",
      "start": 181.2,
      "duration": 3.759
    },
    {
      "text": "recently, like Zuck gutting all of their",
      "start": 183.12,
      "duration": 4.0
    },
    {
      "text": "talent. But OpenAI did get a big win a",
      "start": 184.959,
      "duration": 3.841
    },
    {
      "text": "few days ago when they achieved a gold",
      "start": 187.12,
      "duration": 3.6
    },
    {
      "text": "medal in the International Mathematical",
      "start": 188.8,
      "duration": 3.519
    },
    {
      "text": "Olympiad. What's funny though is that",
      "start": 190.72,
      "duration": 3.36
    },
    {
      "text": "they made a dick move by announcing this",
      "start": 192.319,
      "duration": 3.441
    },
    {
      "text": "before the closing ceremonies of the",
      "start": 194.08,
      "duration": 3.76
    },
    {
      "text": "event in order to overshadow Google and",
      "start": 195.76,
      "duration": 3.92
    },
    {
      "text": "the press, who also achieved gold medal",
      "start": 197.84,
      "duration": 3.6
    },
    {
      "text": "level performance. However, that ended",
      "start": 199.68,
      "duration": 3.36
    },
    {
      "text": "up backfiring because it just made",
      "start": 201.44,
      "duration": 3.28
    },
    {
      "text": "OpenAI look desperate. But if you want",
      "start": 203.04,
      "duration": 3.52
    },
    {
      "text": "to write really good code with AI, you",
      "start": 204.72,
      "duration": 3.519
    },
    {
      "text": "need to check out Code Rabbit, the",
      "start": 206.56,
      "duration": 3.84
    },
    {
      "text": "sponsor of today's video. Their free VS",
      "start": 208.239,
      "duration": 4.08
    },
    {
      "text": "Code extension gives you advanced code",
      "start": 210.4,
      "duration": 3.52
    },
    {
      "text": "reviews right in your editor. And their",
      "start": 212.319,
      "duration": 3.84
    },
    {
      "text": "new fix all with AI feature passes all",
      "start": 213.92,
      "duration": 4.319
    },
    {
      "text": "of Code Rabbit's review context directly",
      "start": 216.159,
      "duration": 4.321
    },
    {
      "text": "to the AI code agent of your choice is",
      "start": 218.239,
      "duration": 4.08
    },
    {
      "text": "so it can make all the changes for you.",
      "start": 220.48,
      "duration": 3.44
    },
    {
      "text": "This saves you from needing to click on",
      "start": 222.319,
      "duration": 3.601
    },
    {
      "text": "each review comment yourself, giving you",
      "start": 223.92,
      "duration": 4.0
    },
    {
      "text": "more time to write even more broken code",
      "start": 225.92,
      "duration": 4.0
    },
    {
      "text": "like a true artisan. Code Rabbit is free",
      "start": 227.92,
      "duration": 4.08
    },
    {
      "text": "to use in the IDE and works seamlessly",
      "start": 229.92,
      "duration": 4.239
    },
    {
      "text": "with VS Code and forks like Cursor and",
      "start": 232.0,
      "duration": 3.92
    },
    {
      "text": "Windsurf. Download it for free with the",
      "start": 234.159,
      "duration": 3.36
    },
    {
      "text": "link below to try it out. This has been",
      "start": 235.92,
      "duration": 3.599
    },
    {
      "text": "the code Report. Thanks for watching and",
      "start": 237.519,
      "duration": 6.041
    },
    {
      "text": "I will see you in the next one.",
      "start": 239.519,
      "duration": 4.041
    }
  ],
  "intro": [
    {
      "text": "Yesterday, Chinese company Alibaba",
      "start": 0.08,
      "duration": 4.08
    },
    {
      "text": "dropped a brand new openweight long",
      "start": 2.32,
      "duration": 4.24
    },
    {
      "text": "horizon mixture of experts agent coding",
      "start": 4.16,
      "duration": 5.04
    },
    {
      "text": "model named Quen 3 coder. And amazingly,",
      "start": 6.56,
      "duration": 4.56
    },
    {
      "text": "it's the first openweight model that",
      "start": 9.2,
      "duration": 3.76
    },
    {
      "text": "matches the programming performance of",
      "start": 11.12,
      "duration": 4.24
    },
    {
      "text": "Claude 4, the undisputed leader of AI",
      "start": 12.96,
      "duration": 4.56
    },
    {
      "text": "vibe coding tools at the present time.",
      "start": 15.36,
      "duration": 4.48
    },
    {
      "text": "Not only is the Quen 3 coder model open,",
      "start": 17.52,
      "duration": 4.16
    },
    {
      "text": "but they also just released a brand new",
      "start": 19.84,
      "duration": 4.0
    },
    {
      "text": "CLI tool forked from the recently open",
      "start": 21.68,
      "duration": 4.16
    },
    {
      "text": "source Gemini CLI that can take",
      "start": 23.84,
      "duration": 3.679
    },
    {
      "text": "advantage of all the models agentic",
      "start": 25.84,
      "duration": 3.92
    },
    {
      "text": "properties like the ability to run,",
      "start": 27.519,
      "duration": 4.16
    },
    {
      "text": "execute, and test your code from the",
      "start": 29.76,
      "duration": 3.92
    },
    {
      "text": "command line. That's terrifying news for",
      "start": 31.679,
      "duration": 3.921
    },
    {
      "text": "any programmer still left with a job,",
      "start": 33.68,
      "duration": 3.92
    },
    {
      "text": "but mathematicians are also on life",
      "start": 35.6,
      "duration": 3.84
    },
    {
      "text": "support right now because both Google",
      "start": 37.6,
      "duration": 4.24
    },
    {
      "text": "and OpenAI just achieved gold medals in",
      "start": 39.44,
      "duration": 4.639
    },
    {
      "text": "the International Mathematical Olympiad.",
      "start": 41.84,
      "duration": 3.84
    },
    {
      "text": "In today's video, we'll take a look at",
      "start": 44.079,
      "duration": 3.521
    },
    {
      "text": "the latest AI breakthroughs and find out",
      "start": 45.68,
      "duration": 4.08
    },
    {
      "text": "if Quen 3 coder can actually compete",
      "start": 47.6,
      "duration": 5.36
    },
    {
      "text": "with Claude 4. It is July 23rd, 2025,",
      "start": 49.76,
      "duration": 5.04
    },
    {
      "text": "and you're watching the code report.",
      "start": 52.96,
      "duration": 3.84
    },
    {
      "text": "Just last week, the open model scene got",
      "start": 54.8,
      "duration": 4.48
    },
    {
      "text": "a big upgrade with the Chinese Kimmy K2,",
      "start": 56.8,
      "duration": 4.72
    },
    {
      "text": "but now Quen 3 coder pushes things even",
      "start": 59.28,
      "duration": 4.64
    }
  ],
  "outro": [
    {
      "text": "talent. But OpenAI did get a big win a",
      "start": 184.959,
      "duration": 3.841
    },
    {
      "text": "few days ago when they achieved a gold",
      "start": 187.12,
      "duration": 3.6
    },
    {
      "text": "medal in the International Mathematical",
      "start": 188.8,
      "duration": 3.519
    },
    {
      "text": "Olympiad. What's funny though is that",
      "start": 190.72,
      "duration": 3.36
    },
    {
      "text": "they made a dick move by announcing this",
      "start": 192.319,
      "duration": 3.441
    },
    {
      "text": "before the closing ceremonies of the",
      "start": 194.08,
      "duration": 3.76
    },
    {
      "text": "event in order to overshadow Google and",
      "start": 195.76,
      "duration": 3.92
    },
    {
      "text": "the press, who also achieved gold medal",
      "start": 197.84,
      "duration": 3.6
    },
    {
      "text": "level performance. However, that ended",
      "start": 199.68,
      "duration": 3.36
    },
    {
      "text": "up backfiring because it just made",
      "start": 201.44,
      "duration": 3.28
    },
    {
      "text": "OpenAI look desperate. But if you want",
      "start": 203.04,
      "duration": 3.52
    },
    {
      "text": "to write really good code with AI, you",
      "start": 204.72,
      "duration": 3.519
    },
    {
      "text": "need to check out Code Rabbit, the",
      "start": 206.56,
      "duration": 3.84
    },
    {
      "text": "sponsor of today's video. Their free VS",
      "start": 208.239,
      "duration": 4.08
    },
    {
      "text": "Code extension gives you advanced code",
      "start": 210.4,
      "duration": 3.52
    },
    {
      "text": "reviews right in your editor. And their",
      "start": 212.319,
      "duration": 3.84
    },
    {
      "text": "new fix all with AI feature passes all",
      "start": 213.92,
      "duration": 4.319
    },
    {
      "text": "of Code Rabbit's review context directly",
      "start": 216.159,
      "duration": 4.321
    },
    {
      "text": "to the AI code agent of your choice is",
      "start": 218.239,
      "duration": 4.08
    },
    {
      "text": "so it can make all the changes for you.",
      "start": 220.48,
      "duration": 3.44
    },
    {
      "text": "This saves you from needing to click on",
      "start": 222.319,
      "duration": 3.601
    },
    {
      "text": "each review comment yourself, giving you",
      "start": 223.92,
      "duration": 4.0
    },
    {
      "text": "more time to write even more broken code",
      "start": 225.92,
      "duration": 4.0
    },
    {
      "text": "like a true artisan. Code Rabbit is free",
      "start": 227.92,
      "duration": 4.08
    },
    {
      "text": "to use in the IDE and works seamlessly",
      "start": 229.92,
      "duration": 4.239
    },
    {
      "text": "with VS Code and forks like Cursor and",
      "start": 232.0,
      "duration": 3.92
    },
    {
      "text": "Windsurf. Download it for free with the",
      "start": 234.159,
      "duration": 3.36
    },
    {
      "text": "link below to try it out. This has been",
      "start": 235.92,
      "duration": 3.599
    },
    {
      "text": "the code Report. Thanks for watching and",
      "start": 237.519,
      "duration": 6.041
    },
    {
      "text": "I will see you in the next one.",
      "start": 239.519,
      "duration": 4.041
    }
  ],
  "main_samples": [
    {
      "timestamp": 90.89,
      "duration": 30,
      "text": "think of Quen's training infrastructure like a coding boot camp with 20,000 graduates all working on the same problem simultaneously, except they never get tired, never argue, and never ask, \"Is this a breaking change?\" And the end result speaks for itself in these benchmarks. Based on this benchmark, Quen is outperforming Kimmy and GPT4.1 and almost on par with Claude 4, but doing so with a much smaller model size, which is important because the bigger the model, the more electricity and GPUs you need to run it. What's also really impressive about Quen",
      "entries": [
        {
          "text": "think of Quen's training infrastructure",
          "start": 92.4,
          "duration": 3.759
        },
        {
          "text": "like a coding boot camp with 20,000",
          "start": 94.0,
          "duration": 3.68
        },
        {
          "text": "graduates all working on the same",
          "start": 96.159,
          "duration": 3.361
        },
        {
          "text": "problem simultaneously, except they",
          "start": 97.68,
          "duration": 4.0
        },
        {
          "text": "never get tired, never argue, and never",
          "start": 99.52,
          "duration": 3.919
        },
        {
          "text": "ask, \"Is this a breaking change?\" And",
          "start": 101.68,
          "duration": 3.28
        },
        {
          "text": "the end result speaks for itself in",
          "start": 103.439,
          "duration": 3.121
        },
        {
          "text": "these benchmarks. Based on this",
          "start": 104.96,
          "duration": 3.6
        },
        {
          "text": "benchmark, Quen is outperforming Kimmy",
          "start": 106.56,
          "duration": 5.199
        },
        {
          "text": "and GPT4.1 and almost on par with Claude",
          "start": 108.56,
          "duration": 5.28
        },
        {
          "text": "4, but doing so with a much smaller",
          "start": 111.759,
          "duration": 4.0
        },
        {
          "text": "model size, which is important because",
          "start": 113.84,
          "duration": 3.279
        },
        {
          "text": "the bigger the model, the more",
          "start": 115.759,
          "duration": 3.601
        },
        {
          "text": "electricity and GPUs you need to run it.",
          "start": 117.119,
          "duration": 4.081
        },
        {
          "text": "What's also really impressive about Quen",
          "start": 119.36,
          "duration": 4.96
        }
      ]
    },
    {
      "timestamp": 121.78,
      "duration": 30,
      "text": "context window that can stretch up to 1 million tokens. For reference, that's enough to hold the entire codebase of most startups and all of their technical debt. Quen 3 coder is an openweight model, but if you think you're going to run it locally on your laptop, it's time for a reality check. To harness the full girth of the 480 billion parameter version, you would need tens of thousands, if not hundreds of thousands of dollars worth of GPUs along with a large wallet to pay the electricity bill. Realistically, to try it, you'd want to get an API key from a cloud provider, then hook it up to the new",
      "entries": [
        {
          "text": "context window that can stretch up to 1",
          "start": 124.32,
          "duration": 3.999
        },
        {
          "text": "million tokens. For reference, that's",
          "start": 126.32,
          "duration": 3.6
        },
        {
          "text": "enough to hold the entire codebase of",
          "start": 128.319,
          "duration": 3.441
        },
        {
          "text": "most startups and all of their technical",
          "start": 129.92,
          "duration": 3.76
        },
        {
          "text": "debt. Quen 3 coder is an openweight",
          "start": 131.76,
          "duration": 3.199
        },
        {
          "text": "model, but if you think you're going to",
          "start": 133.68,
          "duration": 3.199
        },
        {
          "text": "run it locally on your laptop, it's time",
          "start": 134.959,
          "duration": 4.081
        },
        {
          "text": "for a reality check. To harness the full",
          "start": 136.879,
          "duration": 4.241
        },
        {
          "text": "girth of the 480 billion parameter",
          "start": 139.04,
          "duration": 3.52
        },
        {
          "text": "version, you would need tens of",
          "start": 141.12,
          "duration": 3.119
        },
        {
          "text": "thousands, if not hundreds of thousands",
          "start": 142.56,
          "duration": 3.759
        },
        {
          "text": "of dollars worth of GPUs along with a",
          "start": 144.239,
          "duration": 3.521
        },
        {
          "text": "large wallet to pay the electricity",
          "start": 146.319,
          "duration": 3.361
        },
        {
          "text": "bill. Realistically, to try it, you'd",
          "start": 147.76,
          "duration": 3.6
        },
        {
          "text": "want to get an API key from a cloud",
          "start": 149.68,
          "duration": 3.279
        },
        {
          "text": "provider, then hook it up to the new",
          "start": 151.36,
          "duration": 3.92
        }
      ]
    },
    {
      "timestamp": 152.67000000000002,
      "duration": 30,
      "text": "Quen CLI tool, which again is a fork of the Gemini CLI. Overall, this does appear to be a big leap forward for open coding models. But I doubt that it will make much of a dent in Claude's dominance in the coding world. To be Claude, a company needs to release a model that's not only open and inexpensive, but that surpasses Claude's capabilities by a significant margin. Like OpenAI was recently supposed to release its own Open model, but that's been delayed with the rumor for the delay being that these Chinese models would absolutely crush it. That's just one of many L's taken by OpenAI",
      "entries": [
        {
          "text": "Quen CLI tool, which again is a fork of",
          "start": 152.959,
          "duration": 4.401
        },
        {
          "text": "the Gemini CLI. Overall, this does",
          "start": 155.28,
          "duration": 4.0
        },
        {
          "text": "appear to be a big leap forward for open",
          "start": 157.36,
          "duration": 3.84
        },
        {
          "text": "coding models. But I doubt that it will",
          "start": 159.28,
          "duration": 3.36
        },
        {
          "text": "make much of a dent in Claude's",
          "start": 161.2,
          "duration": 3.2
        },
        {
          "text": "dominance in the coding world. To be",
          "start": 162.64,
          "duration": 3.52
        },
        {
          "text": "Claude, a company needs to release a",
          "start": 164.4,
          "duration": 3.199
        },
        {
          "text": "model that's not only open and",
          "start": 166.16,
          "duration": 3.84
        },
        {
          "text": "inexpensive, but that surpasses Claude's",
          "start": 167.599,
          "duration": 4.481
        },
        {
          "text": "capabilities by a significant margin.",
          "start": 170.0,
          "duration": 4.08
        },
        {
          "text": "Like OpenAI was recently supposed to",
          "start": 172.08,
          "duration": 3.84
        },
        {
          "text": "release its own Open model, but that's",
          "start": 174.08,
          "duration": 3.439
        },
        {
          "text": "been delayed with the rumor for the",
          "start": 175.92,
          "duration": 3.44
        },
        {
          "text": "delay being that these Chinese models",
          "start": 177.519,
          "duration": 3.681
        },
        {
          "text": "would absolutely crush it. That's just",
          "start": 179.36,
          "duration": 3.76
        },
        {
          "text": "one of many L's taken by OpenAI",
          "start": 181.2,
          "duration": 3.759
        }
      ]
    }
  ],
  "transcript_length": 124,
  "fetched_at": "2025-07-27T12:37:27.313687"
}